{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bed22c-3267-4755-89f2-fd5a96a61edc",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ceeb023-9862-4a7b-a910-34d988e07162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa5990-a26a-48f1-838e-8cad44529269",
   "metadata": {},
   "source": [
    "Initialize the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be06aa8e-c945-47b9-90c2-ee2cbdeb33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812db17b-72e9-4333-a198-dd211a557d1d",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407f308b-8adb-49b4-bb89-01a1a00ef395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561eafd2-0cc6-46c5-81f6-8f3cc81a8b2b",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c788a1d8-4fc3-415d-9cfa-fc293513a9da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'sources': {'hf': 'Qdrant/fast-bge-base-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.42,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.21,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-zh-v1.5',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.43,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.54,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.02,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-clip-v1',\n",
       "  'sources': {'hf': 'jinaai/jina-clip-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/text_model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.55,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.25,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.12,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_fp16.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.32,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-es',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-es',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-base',\n",
       "  'sources': {'hf': 'thenlper/gte-base',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.44,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_quantized.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.22,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.0,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'sources': {'hf': 'qdrant/multilingual-e5-large-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 2.24,\n",
       "  'additional_files': ['model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v3',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v3',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'size_in_GB': 2.29,\n",
       "  'additional_files': ['onnx/model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {'retrieval.query': 0,\n",
       "   'retrieval.passage': 1,\n",
       "   'separation': 2,\n",
       "   'classification': 3,\n",
       "   'text-matching': 4}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97256b2-5b4b-40f0-aab4-24e0546773d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d783d0-5547-4ffe-ab06-93107b6eb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffe995-2463-4ed1-8fec-9e1b7c52f1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae5fa594-ac2c-4e60-872c-92d9fc1d0b7d",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7991b1c-f128-4cba-aeea-49be9bd1703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a0070-ddc9-4276-9967-ff948c1e947c",
   "metadata": {},
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11877e0-bd7e-4785-8b18-b507d65f2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=models.Document(text=doc['text'], model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed1fa5b-e821-485c-a9cf-a1d2dec0aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0c9b7-8a29-4b00-bf0d-2d4c331b9f92",
   "metadata": {},
   "source": [
    "To visualize: Head here:\n",
    "\n",
    "http://127.0.0.1:6333/dashboard#/collections/zoomcamp-rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2e5d9-d6eb-43dc-b051-19347e999777",
   "metadata": {},
   "source": [
    "## Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1732e7ec-6084-49c7-9371-58816f649fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1f0869-28b0-41e9-aaad-f48a07f833aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"When try to add three assertions:\\nvendor_id is one of the existing values in the column (currently)\\npassenger_count is greater than 0\\ntrip_distance is greater than 0\\nto test_output, I got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). Below is my code:\\ndata_filter = (data['passenger_count'] > 0) and (data['trip_distance'] > 0)\\nAfter looking for solutions at Stackoverflow, I found great discussion about it. So I changed my code into:\\ndata_filter = (data['passenger_count'] > 0) & (data['trip_distance'] > 0)\",\n",
      "  \"section\": \"Module 2: Workflow Orchestration\",\n",
      "  \"question\": \"Got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course['documents'])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "421e2da0-cf5f-4316-9822-773ffd2e1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(course_piece['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cca5827-2482-4d81-aed1-68d26e17fa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=192, version=1, score=0.87244636, payload={'text': \"When try to add three assertions:\\nvendor_id is one of the existing values in the column (currently)\\npassenger_count is greater than 0\\ntrip_distance is greater than 0\\nto test_output, I got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). Below is my code:\\ndata_filter = (data['passenger_count'] > 0) and (data['trip_distance'] > 0)\\nAfter looking for solutions at Stackoverflow, I found great discussion about it. So I changed my code into:\\ndata_filter = (data['passenger_count'] > 0) & (data['trip_distance'] > 0)\", 'section': 'Module 2: Workflow Orchestration', 'course': 'data-engineering-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f7a1a4-7b45-41f9-aae7-07c612f03fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()\n",
      "\n",
      "Top Retrieved Answer:\n",
      "When try to add three assertions:\n",
      "vendor_id is one of the existing values in the column (currently)\n",
      "passenger_count is greater than 0\n",
      "trip_distance is greater than 0\n",
      "to test_output, I got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). Below is my code:\n",
      "data_filter = (data['passenger_count'] > 0) and (data['trip_distance'] > 0)\n",
      "After looking for solutions at Stackoverflow, I found great discussion about it. So I changed my code into:\n",
      "data_filter = (data['passenger_count'] > 0) & (data['trip_distance'] > 0)\n",
      "\n",
      "Original Answer:\n",
      "When try to add three assertions:\n",
      "vendor_id is one of the existing values in the column (currently)\n",
      "passenger_count is greater than 0\n",
      "trip_distance is greater than 0\n",
      "to test_output, I got ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). Below is my code:\n",
      "data_filter = (data['passenger_count'] > 0) and (data['trip_distance'] > 0)\n",
      "After looking for solutions at Stackoverflow, I found great discussion about it. So I changed my code into:\n",
      "data_filter = (data['passenger_count'] > 0) & (data['trip_distance'] > 0)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\\n{course_piece['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\".format(course_piece['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "285dabe0-becc-469b-a95c-20dd508fbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "print(search(\"What if I submit homeworks late?\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b2a20-1786-4481-aa07-39d67a35a5c1",
   "metadata": {},
   "source": [
    "## Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5add7a8-2a9a-435e-9d28-17fc8e6103b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=3, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3a67713-e84b-4c4b-be54-652db2e3ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course=\"mlops-zoomcamp\", limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "354db94d-e336-43fc-bd4d-25f312c5e1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the closest one to your answer. Also do not post your answer in the course slack channel.\n"
     ]
    }
   ],
   "source": [
    "print(search_in_course(\"What if I submit homeworks late?\", \"mlops-zoomcamp\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ef59e-e71a-4809-b7c2-d87dadee249f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
